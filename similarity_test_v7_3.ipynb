{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "467105ae-42da-4dc3-b1c6-b4cbfc9488b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************ The code is loaded ************\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\"\"\"\n",
    "Author: Mrinal Kanti Dhar\n",
    "December 12, 2024\n",
    "\"\"\"\n",
    "\n",
    "# * v6: Color blending added\n",
    "# * v7: Parameter keep_only is changed to keep_range\n",
    "# * v7_2: Predictions are read from the excel file\n",
    "# * v7_3: Generate confidence score based on PCA/t-SNE and model outputs\n",
    "\n",
    "print('************ The code is loaded ************')\n",
    "\n",
    "import warnings\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Append paths\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.getcwd() + '/networks/') \n",
    "sys.path.append(os.getcwd() + '/utils/') \n",
    "sys.path.append(os.getcwd() + '/dataloader/') \n",
    "sys.path.append(os.getcwd() + '/losses/') \n",
    "sys.path.append(os.getcwd() + '/config/') \n",
    "\n",
    "from read_ultrasound import read_nib\n",
    "\n",
    "import cv2\n",
    "from dataloader.loader import MyDataset\n",
    "import torch\n",
    "from torch import nn\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.models as models\n",
    "from datetime import datetime\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# import albumentations as A\n",
    "\n",
    "from networks import nets\n",
    "from network_parameters.params import model_params\n",
    "from utils import augmentations, normalization\n",
    "from losses.loss import loss_func\n",
    "\n",
    "# from sklearn.metrics import confusion_matrix, classification_report\n",
    "# from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_auc_score\n",
    "# from sklearn.metrics import roc_curve, RocCurveDisplay, auc\n",
    "# from sklearn.preprocessing import label_binarize\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from box import Box\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f571dbdf-e457-47cf-ae24-2ea3423dcacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ### Function to read config file from command line\n",
    "# def get_config_from_args():\n",
    "#     parser = argparse.ArgumentParser(description=\"Pass config file\")\n",
    "#     parser.add_argument('--config', type=str, required=True, help=\"Path to the YAML config file\")\n",
    "#     args = parser.parse_args()\n",
    "#     return args\n",
    "    \n",
    "# # ### Read config file\n",
    "# # Get the config file from command-line arguments\n",
    "# args = get_config_from_args()\n",
    "\n",
    "# with open(args.config, \"r\") as file:\n",
    "#     config = yaml.safe_load(file)\n",
    "# config = Box(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac2b5ef-8c22-4f81-8303-1f7c19fa67e5",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8712af08-d147-4149-afb7-6407f4de4647",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Parameters\n",
    "BASE_MODEL = \"EnsembleResNet18Ft512_EfficientNetB2SFt1408\" # config.model.name\n",
    "\n",
    "base_model_name = \"EnsembleResNet18Ft512_EfficientNetB2SFt1408_2024-10-25_17-31-23\" # config.test.base_model_name\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "LR = 0.001 # config.train.lr #0.0001 # learning rate\n",
    "WEIGHT_DECAY = 0.001 # config.train.weight_decay #1e-5\n",
    "\n",
    "BATCH_SIZE = 1 # config.train.batch_size\n",
    "ONE_HOT = True # config.train.one_hot\n",
    "N_CLASSES = 2 # config.train.n_classes\n",
    "ONLY_ADNEXAL = False # config.data.only_adnexal\n",
    "ONLY_FLUID = True # config.data.only_fluid\n",
    "ONLY_SOLID = True # config.data.only_solid\n",
    "DRAW_BBOX = False # config.data.draw_bbox\n",
    "CROP_ROI = True # config.data.crop_roi\n",
    "MARGIN = 200 # config.data.margin\n",
    "RESIZE = True # config.data.resize\n",
    "KEEP_ASPECT_RATIO = True # config.data.keep_aspect_ratio\n",
    "TARGET_SIZE = [224,224] # config.data.target_size\n",
    "CONCAT = [\"image\", \"fluid\", \"solid\"] # config.data.concat # Possible keywords are: \"image\", \"adnexal\", \"fluid\", \"solid\", \"mask\"\n",
    "INPUT_CH = len(CONCAT)\n",
    "\n",
    "N_FOLDS = 5\n",
    "\n",
    "# Parameters for ensemble models\n",
    "DROPOUT = 0.3 # config.model.dropout\n",
    "OUT_CHS = [5376, 1024, 512, 256] # config.model.out_channels # concat feature maps will be converted to OUT_CHS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07be9e63-9df5-42e1-afb2-3405c885095e",
   "metadata": {},
   "source": [
    "### Image directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "125c1bcd-52d9-40e4-8978-42e8e4be1022",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/research/m324371/Project/adnexal/\" # config.directories.root\n",
    "result_dir = \"/research/m324371/Project/adnexal/results/\" # config.directories.result_dir\n",
    "train_im_dir = \"/research/m324371/Project/adnexal/dataset/train/\" # config.directories.train_im_dir\n",
    "val_im_dir = \"/research/m324371/Project/adnexal/dataset/train/\" # config.directories.val_im_dir\n",
    "test_im_dir = \"/research/m324371/Project/adnexal/dataset/test/\" # config.directories.test_im_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27feab57-736d-4183-8ad6-b6aaef0325b0",
   "metadata": {},
   "source": [
    "### Read the test result excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc0638d2-9b2d-4abb-862a-286ef91ecb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = pd.read_excel(os.path.join(result_dir, base_model_name, \"results_test\", base_model_name + \"_avg.xlsx\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cd24f9-8855-4a3f-b8c5-bcfeb5231b8b",
   "metadata": {},
   "source": [
    "### Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ad7faae-c010-4531-b5cc-b846caf02eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "normalize_transform = normalization.normalize_v2(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # always normalize\n",
    "\n",
    "# Augmentation\n",
    "transform = augmentations.transforms()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d8b9d6-a513-4d16-b216-f1fe40f21b71",
   "metadata": {},
   "source": [
    "### Prepare preprocessing dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3495a1e6-4001-4e12-b004-f03cae6502c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_dict = {}\n",
    "pp_dict[\"only_adnexal\"] = ONLY_ADNEXAL\n",
    "pp_dict[\"only_fluid\"] = ONLY_FLUID\n",
    "pp_dict[\"only_solid\"] = ONLY_SOLID\n",
    "pp_dict[\"draw_bbox\"] = DRAW_BBOX\n",
    "pp_dict[\"crop_roi\"] = CROP_ROI\n",
    "pp_dict[\"margin\"] = MARGIN\n",
    "pp_dict[\"resize\"] = RESIZE\n",
    "pp_dict[\"keep_aspect_ratio\"] = KEEP_ASPECT_RATIO\n",
    "pp_dict[\"target_size\"] = TARGET_SIZE\n",
    "\n",
    "# For training data\n",
    "train_pp_dict = pp_dict.copy()\n",
    "train_pp_dict[\"file_dir\"] = train_im_dir\n",
    "\n",
    "# For validation data\n",
    "val_pp_dict = pp_dict.copy()\n",
    "val_pp_dict[\"file_dir\"] = val_im_dir\n",
    "\n",
    "# For test data\n",
    "test_pp_dict = pp_dict.copy()\n",
    "test_pp_dict[\"file_dir\"] = test_im_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758e4197-00c1-4db2-920b-b338c1ad4094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Read adnexal_dataset.xlsx\n",
    "# Read adnexal dataset.xlsx\n",
    "df_location = '/research/m324371/Project/adnexal/adnexal_dataset_all.xlsx' # config.directories.excel_dir\n",
    "dataframe = pd.read_excel(df_location, sheet_name=None) \n",
    "\n",
    "# Read train and test sheets\n",
    "df_train = dataframe['train']  \n",
    "df_test = dataframe['test']  \n",
    "\n",
    "print(df_train.head())\n",
    "\n",
    "train_names = df_train['Base names']\n",
    "train_class = df_train['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fbd592-6474-4528-a4a2-257291948bd5",
   "metadata": {},
   "source": [
    "### Pick test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcd576fd-a482-4a1c-b25b-1ec36f734cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Uncomment if you want selected test images by their indices\n",
    "# test_idx = [66, 114, 160]\n",
    "# df_test = df_test.iloc[test_idx]\n",
    "# df_test.reset_index(drop=True, inplace=True) # Reset index. Start from 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175a3cdb-57c0-4397-a8bb-f4903744b5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_names = list(df_test[\"Base names\"])\n",
    "\n",
    "print('Test names:', test_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c08da3-8d3c-4ca9-a164-e00b92fd6c6a",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47ba511e-846f-4182-91c8-6d6ae730db5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(\n",
    "            df_train, \n",
    "            n_classes=N_CLASSES, \n",
    "            transform=None, \n",
    "            normalize=normalize_transform,\n",
    "            one_hot=ONE_HOT,\n",
    "            preprocess_dict=train_pp_dict,\n",
    "            concat=CONCAT,\n",
    "            )\n",
    "    \n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=1)\n",
    "\n",
    "test_dataset = MyDataset(\n",
    "            df_test, \n",
    "            n_classes=N_CLASSES, \n",
    "            transform=None, \n",
    "            normalize=normalize_transform,\n",
    "            one_hot=ONE_HOT,\n",
    "            preprocess_dict=test_pp_dict,\n",
    "            concat=CONCAT,\n",
    "            )\n",
    "    \n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0b4ef5-4d43-49df-988f-71ce6d274340",
   "metadata": {},
   "source": [
    "### Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00c26abe-25dd-4483-b683-b0a9b88d599e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamically get the model class from nets\n",
    "# get_model = getattr(nets, config.model.name) # get_model is a model class, not an object\n",
    "\n",
    "# params = model_params(config.model.name, config) # initialize the model with other parameters \n",
    "\n",
    "# base_model = get_model(**params)\n",
    "\n",
    "get_model = getattr(nets, BASE_MODEL) # get_model is a model class, not an object\n",
    "params = dict()\n",
    "params[\"num_classes\"] = N_CLASSES\n",
    "params[\"out_channels\"] = OUT_CHS\n",
    "params[\"pretrain\"] = True\n",
    "params[\"dropout\"] = DROPOUT \n",
    "params[\"in_chs\"] = len(CONCAT) # len(config.data.concat) # <<<<<<<<<<<<<<<<<<<<<<<<<<<<< temporarily changed for doppler\n",
    "params[\"separate_inputs\"] = 3 # config.model.separate_inputs\n",
    "base_model = get_model(**params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd09ec3-b216-43f9-b691-399a33f02b18",
   "metadata": {},
   "source": [
    "### Test save directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d36d4f4c-1f13-4181-82c1-6b683b46db81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model_name = 'resnet18_imsize256_2024-09-25_16-55-17'\n",
    "test_save_dir = os.path.join(result_dir, base_model_name, 'results_test', 'similarity_test_v7-3_top5')\n",
    "os.makedirs(test_save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d7d1b5-211e-4a3e-b126-d9b30dc00b16",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4babc7bd-7db8-498c-9b54-3c6ed8753165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best model name from the k-fold summary report\n",
    "dir_excel = os.path.join(result_dir, base_model_name, 'results_val')\n",
    "file_name = base_model_name + '_val.xlsx'\n",
    "\n",
    "dataframe = pd.read_excel(os.path.join(dir_excel, file_name), sheet_name=None)\n",
    "\n",
    "metric, folds = [], []\n",
    "\n",
    "for sheet_name, dframe in dataframe.items():\n",
    "    first_row = dframe.iloc[0]\n",
    "    metric.append(first_row[\"Accuracy\"])\n",
    "    folds.append(sheet_name)\n",
    "                  \n",
    "best_metric_idx = np.argmax(metric)\n",
    "best_model_name = dataframe[folds[best_metric_idx]][\"Model name\"][0]\n",
    "best_epoch = dataframe[folds[best_metric_idx]][\"Best epoch\"][0]\n",
    "\n",
    "print('Base model name:', base_model_name)\n",
    "print('Best model index:', best_metric_idx)\n",
    "print('Best epoch:', best_epoch)\n",
    "print('Best model name:', best_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b929f7-222f-4de2-8d46-af89fc75e11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all model names\n",
    "model_names = []\n",
    "for fold in folds:\n",
    "    model_name = dataframe[fold][\"Model name\"][0]\n",
    "    model_names.append(model_name)\n",
    "\n",
    "print(model_names)\n",
    "\n",
    "# Define hook function globally or outside the loop\n",
    "features = []  # Global list to store features\n",
    "\n",
    "def hook(module, input, output):\n",
    "    features.append(output.clone().detach().cpu())  # Store hooked output safely\n",
    "\n",
    "# Attach hooks to models and process\n",
    "trained_models = []\n",
    "\n",
    "for model_name in model_names:\n",
    "    checkpoint_loc = os.path.join(result_dir, base_model_name, 'checkpoints', model_name)\n",
    "    checkpoint = torch.load(os.path.join(checkpoint_loc, 'best_model.pth'))\n",
    "\n",
    "    # Make a deep copy of the base model\n",
    "    model_copy = deepcopy(base_model)\n",
    "\n",
    "    # Load the weights into the copied model\n",
    "    model_copy.load_state_dict(checkpoint['state_dict'])\n",
    "    model_copy.eval()  # Set the copied model to evaluation mode\n",
    "\n",
    "    # Attach hook to capture features from an intermediate layer\n",
    "    layer_to_hook = model_copy.classification.avg_pool # layer to hook <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "    layer_to_hook.register_forward_hook(hook)\n",
    "\n",
    "    # Append the copied model to the list of trained models\n",
    "    trained_models.append(model_copy.to(DEVICE))\n",
    "\n",
    "print(f\"No. of models: {len(trained_models)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cdb0f8-359f-40b1-a394-85248b8cbcb5",
   "metadata": {},
   "source": [
    "### Generate features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb585b3-badf-4451-a43b-8f3245babc6c",
   "metadata": {},
   "source": [
    "#### For training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d565f9-6856-4951-9387-8dea31efe22e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For train data\n",
    "store_train_features = []  # Store features for all training images\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, labels, names) in tqdm(enumerate(train_loader)):\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "\n",
    "        if ONE_HOT:\n",
    "            labels = torch.argmax(labels, dim=1).data.cpu().numpy().tolist()\n",
    "        else:\n",
    "            labels = labels.data.cpu().numpy().squeeze()\n",
    "\n",
    "        store_pred = []\n",
    "        for model_idx, model in enumerate(trained_models):\n",
    "\n",
    "            features.clear()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs_ = model(inputs)\n",
    "\n",
    "            # Handle hooked features\n",
    "            if len(features) > 0:\n",
    "                hooked_features = features[0].numpy()\n",
    "                for b in range(hooked_features.shape[0]):  # Iterate over batch\n",
    "                    hooked_features_batch = hooked_features[b].squeeze().tolist()\n",
    "                    store_pred.append([names[b], labels[b], hooked_features_batch, model_idx]) # stores per-model\n",
    "            else:\n",
    "                print(\"Warning: Hook did not capture training features\")\n",
    "\n",
    "        store_train_features.append(store_pred) # stores for all models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748d066c-4e5a-4b62-acc7-06d09d8f7f19",
   "metadata": {},
   "source": [
    "#### For testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35acc46-9f19-4ad7-a9e5-55657afcde90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For test data\n",
    "store_test_features = []  # Store features for all test images\n",
    "with torch.no_grad():\n",
    "    for i, (tinputs, tlabels, tnames) in tqdm(enumerate(test_loader)):\n",
    "        tinputs = tinputs.to(DEVICE)\n",
    "        tlabels = tlabels.to(DEVICE)\n",
    "\n",
    "        if ONE_HOT:\n",
    "            tlabels = torch.argmax(tlabels, dim=1).data.cpu().numpy().tolist()\n",
    "        else:\n",
    "            tlabels = tlabels.data.cpu().numpy().squeeze().tolist()\n",
    "\n",
    "        store_pred = []\n",
    "        for model_idx, model in enumerate(trained_models):\n",
    "            features.clear()\n",
    "\n",
    "            # Forward pass\n",
    "            toutputs = model(tinputs)\n",
    "\n",
    "            # Probabilities \n",
    "            prob = torch.softmax(toutputs, dim=1) if ONE_HOT else torch.sigmoid(toutputs)\n",
    "\n",
    "            # Get predictions\n",
    "            if ONE_HOT:\n",
    "                pred_class = torch.argmax(torch.softmax(prob, dim=1), dim=1).data.cpu().numpy().tolist()\n",
    "            else:\n",
    "                # toutputs.size(1) == 1:  # Binary classification\n",
    "                pred_class = (torch.sigmoid(prob) > 0.5).data.cpu().numpy().squeeze().tolist()\n",
    "\n",
    "            # Handle hooked features\n",
    "            if len(features) > 0:\n",
    "                hooked_features = features[0].numpy()\n",
    "                for b in range(hooked_features.shape[0]):  # Iterate over batch\n",
    "                    hooked_features_batch = hooked_features[b].squeeze().tolist()\n",
    "                    store_pred.append([tnames[b], tlabels[b], hooked_features_batch, pred_class[b], model_idx])  # stores per-model\n",
    "            else:\n",
    "                print(\"Warning: Hook did not capture test features\")\n",
    "\n",
    "        store_test_features.append(store_pred)  # stores all models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e34fb45-8050-427d-9ad9-2c28262489c1",
   "metadata": {},
   "source": [
    "### Similarity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41706597-a543-47d5-9bcb-9375a8b96ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "# Lists to store results\n",
    "detailed_results = []\n",
    "average_scores = []\n",
    "\n",
    "# Iterate over each test sample\n",
    "for test_features in tqdm(store_test_features):  # Features for one test sample\n",
    "    test_name = test_features[0][0]  # Extract the test image name\n",
    "    test_label = test_features[0][1] # Extract true label of the test image\n",
    "    # test_pred = test_features[0][3] # Extract test prediction %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "    # predictions_ = [test_features[i][3] for i in range(N_FOLDS)] # len(train_features) is basically no. of models. Because it is a list that contains lists equal to no. models.\n",
    "    # frequency = Counter(predictions_)\n",
    "    # test_pred = frequency.most_common(1)[0][0]\n",
    "    test_pred = int(test_results.loc[test_results[\"Names\"]==test_name][\"Prediction\"].values)\n",
    "\n",
    "    # Initialize accumulators for averaging scores\n",
    "    total_cosine_sim = 0\n",
    "    total_mse = 0\n",
    "    num_comparisons = 0\n",
    "\n",
    "    for train_features in store_train_features:  # Features for one training sample\n",
    "        train_name = train_features[0][0]  # Extract the train image name\n",
    "        train_label = train_features[0][1] # Extract train image label\n",
    "\n",
    "        # Calculate cosine similarity and MSE for outputs from all models\n",
    "        for i in range(N_FOLDS):  # Assuming 5 models. \n",
    "            # len(train_features) is basically no. of models. Because it is a list that contains lists equal to no. models.\n",
    "            train_output = np.array(train_features[i][2])\n",
    "            test_output = np.array(test_features[i][2])\n",
    "\n",
    "            # Cosine Similarity\n",
    "            cos_sim = np.dot(train_output, test_output) / (\n",
    "                np.linalg.norm(train_output) * np.linalg.norm(test_output)\n",
    "            )\n",
    "\n",
    "            # Mean Squared Error (MSE)\n",
    "            mse = np.mean((train_output - test_output) ** 2)\n",
    "\n",
    "            # Accumulate scores for averaging\n",
    "            total_cosine_sim += cos_sim\n",
    "            total_mse += mse\n",
    "            num_comparisons += 1\n",
    "\n",
    "            # Store individual comparison results\n",
    "            detailed_results.append({\n",
    "                \"Test_Image\": test_name,\n",
    "                \"Train_Image\": train_name,\n",
    "                \"Test_Label\": test_label,\n",
    "                \"Test_Prediction\": test_pred,\n",
    "                \"Train_Label\": train_label,\n",
    "                \"Model_Index\": i,\n",
    "                \"Cosine_Similarity\": cos_sim,\n",
    "                \"MSE\": mse\n",
    "            })\n",
    "\n",
    "    # Store average scores for the current test image\n",
    "    average_scores.append({\n",
    "        \"Test_Image\": test_name, # >>>>>>>>>>> for batchsize=1, test_name is like ('PN0253_34_20190312',). So, put test_name[0]\n",
    "        \"Average_Cosine_Similarity\": total_cosine_sim / num_comparisons,\n",
    "        \"Average_MSE\": total_mse / num_comparisons\n",
    "    })\n",
    "\n",
    "# Convert results to DataFrames\n",
    "detailed_results_df = pd.DataFrame(detailed_results)\n",
    "average_scores_df = pd.DataFrame(average_scores)\n",
    "\n",
    "# Save results to an Excel file with two sheets\n",
    "output_filename = os.path.join(test_save_dir, \"train_test_similarity_\" + datetime.now().strftime('%Y-%m-%d_%H-%M-%S') + \".xlsx\")\n",
    "with pd.ExcelWriter(output_filename, engine='xlsxwriter') as writer:\n",
    "    detailed_results_df.to_excel(writer, sheet_name='Detailed Results', index=False)\n",
    "    average_scores_df.to_excel(writer, sheet_name='Average Scores', index=False)\n",
    "\n",
    "print(f\"Results saved to {output_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d389af-6350-4144-841a-f7ab8396d45a",
   "metadata": {},
   "source": [
    "### Filter data by the patient name and model index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a99ee322-e7a6-4dd6-8681-3f53f8e70b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read image\n",
    "def read_image(file_dir, img_name):\n",
    "    data = read_nib(os.path.join(file_dir, img_name), target_orientation = np.array([[1, -1], [0, -1], [2, -1]]))\n",
    "    data = data.squeeze().astype('uint8')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b697764-5ad5-4bd8-b83a-dc6113293a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_blend(image, mask, mask_color:list=[255, 0, 0], transparency_factor:float=0.5):\n",
    "    \"\"\"\n",
    "    Args\n",
    "    ================\n",
    "    image: Shape HxWxCh or HxW. \n",
    "    mask: Shape HxW.\n",
    "    mask_color: Color that will be assigned to the mask.\n",
    "    transparency_factor: Controls transparency. \n",
    "    \"\"\"\n",
    "\n",
    "    # Convert the grayscale image to a 3-channel RGB image for overlay\n",
    "    if len(image.shape)==2 or image.shape[-1]==1: image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    # Create a color for the mask overlay\n",
    "    mask_color = np.array(mask_color)  # Red color in RGB\n",
    "\n",
    "    # Create a color overlay using the binary mask\n",
    "    color_overlay = np.zeros_like(image, dtype=np.uint8)\n",
    "    color_overlay[mask > 0] = mask_color\n",
    "    \n",
    "    # Blend the image with the color overlay\n",
    "    blended = cv2.addWeighted(image, 1 - transparency_factor, color_overlay, transparency_factor, 0)\n",
    "\n",
    "    return blended\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "081841de-4621-4089-8637-b685b6e24e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_similarity(similarity_df, patient_name, n_folds,\n",
    "                    train_im_dir, test_im_dir, save_dir,\n",
    "                    sort_by:str='Cosine_Similarity', keep_range:tuple=(0,4),  \n",
    "                    blend:bool=True, visualize:bool=False):\n",
    "\n",
    "    \"Part I: Store top similarities for each model in a dataframe.\"\n",
    "    # No. of training images to keep\n",
    "    n_imgs = keep_range[1] - keep_range[0] + 1\n",
    "    \n",
    "    # Create model indices. For 5-fold CV, [0,1,2,3,4]\n",
    "    model_inds = np.arange(0, n_folds).tolist()\n",
    "    \n",
    "    # Create a dataframe to store top similarities for each model\n",
    "    columns = similarity_df.columns.tolist() \n",
    "    top_similarity_df = pd.DataFrame(columns=columns)\n",
    "    \n",
    "    # Load test image\n",
    "    test_image = read_image(test_im_dir, patient_name + \"_image.nii.gz\")\n",
    "       \n",
    "    for model_idx in model_inds:\n",
    "        # Filter dataframe based on patient name and model index\n",
    "        filtered_rows = similarity_df[(similarity_df['Test_Image'] == patient_name) & (similarity_df['Model_Index'] == model_idx)]\n",
    "    \n",
    "        # Check if the range is valid\n",
    "        length = len(filtered_rows)\n",
    "        if keep_range[0] < 0 or keep_range[1] >= length:\n",
    "            raise ValueError(f\"Invalid range. keep_range should be between 0 to {length-1} inclusive.\")\n",
    "    \n",
    "        # Sort data in ascending or descending order\n",
    "        if sort_by == 'Cosine_Similarity': ascending = False\n",
    "        elif sort_by == 'MSE': ascending = True\n",
    "        else: raise ValueError(\"Unsupported name for the argument sort_by. Supported names are Cosine_Similarity and MSE.\")\n",
    "            \n",
    "        sorted_filtered_rows = filtered_rows.sort_values(by=sort_by, ascending=ascending).reset_index(drop=True)\n",
    "        \n",
    "        # Keep top rows only\n",
    "        keep_only_sorted_filtered_rows = sorted_filtered_rows.iloc[keep_range[0]:keep_range[1]+1] # 1 added because end is exclusive\n",
    "    \n",
    "        top_similarity_df = pd.concat([top_similarity_df, keep_only_sorted_filtered_rows], ignore_index=True)\n",
    "    \n",
    "    \n",
    "    \"Part II: Plot the test image and top similarities in the training set at the image level.\"\n",
    "    # Create a grid for subplots: 1 row per model\n",
    "    fig, axes = plt.subplots(nrows=n_folds + 1, ncols=n_imgs+1, figsize=(20, 6 * n_folds))\n",
    "    fig.suptitle(f\"Similarity Results for {patient_name}\", fontsize=20, y=0.9)\n",
    "    \n",
    "    # Ensure axes is always 2D for consistency\n",
    "    if n_folds == 1:\n",
    "        axes = np.expand_dims(axes, axis=0)\n",
    "    \n",
    "    # Group data based on model index\n",
    "    grouped = top_similarity_df.groupby(\"Model_Index\")\n",
    "    \n",
    "    # Test class\n",
    "    test_label = top_similarity_df[\"Test_Label\"].iloc[0]\n",
    "    test_pred = top_similarity_df[\"Test_Prediction\"].iloc[0]\n",
    "    \n",
    "    # Load test mask\n",
    "    if blend: \n",
    "        mask_color = [255, 0, 0]\n",
    "        transparency_factor = 0.1\n",
    "        test_mask = read_image(test_im_dir, patient_name + \"_mask.nii.gz\")\n",
    "        test_image = color_blend(test_image, test_mask, mask_color=mask_color, transparency_factor=transparency_factor)\n",
    "    \n",
    "    # Iterate over groups\n",
    "    for row_pointer, (key, group) in enumerate(grouped):  # Unpack group into key and DataFrame. key is the Model_Index\n",
    "        # Plot the test image\n",
    "        ax = axes[row_pointer, 0]\n",
    "        ax.imshow(test_image, cmap='gray') if not blend else ax.imshow(test_image)\n",
    "        ax.set_title(f\"Test Image, GT: {test_label}, Pred: {test_pred}, CV: {key + 1}\")  \n",
    "        ax.axis('off')\n",
    "    \n",
    "        # Iterate through the rows of the group DataFrame\n",
    "        for column_pointer, (train_img_name, train_label, model_idx) in enumerate(zip(group[\"Train_Image\"], group[\"Train_Label\"], group[\"Model_Index\"])):\n",
    "            train_image = read_image(train_im_dir, train_img_name + \"_image.nii.gz\")\n",
    "            if blend: \n",
    "                train_mask = read_image(train_im_dir, train_img_name + \"_mask.nii.gz\")\n",
    "                train_image = color_blend(train_image, train_mask, mask_color=mask_color, transparency_factor=transparency_factor)\n",
    "    \n",
    "            ax = axes[row_pointer, column_pointer + 1]  # First column is for the test image\n",
    "            ax.imshow(train_image, cmap='gray') if not blend else ax.imshow(train_image)\n",
    "            # ax.set_title(f\"Train Image {column_pointer + 1}, Label: {train_label}, CV: {model_idx + 1}\")\n",
    "            ax.set_title(f\"{train_img_name}\\n Label: {train_label}, CV: {model_idx + 1}\")\n",
    "            ax.axis('off')\n",
    "    \n",
    "    \"Part III: Find top patient-level similarities from the image-level similarities found in Part II\"\n",
    "    # Sort top_similarity_df\n",
    "    sorted_top_similarity_df = top_similarity_df.sort_values(by=sort_by, ascending=ascending).reset_index(drop=True)\n",
    "        \n",
    "    # Extract patients name from Train_Image and create a new column for it.\n",
    "    # Image name format: patientName_xx_xxxxx\n",
    "    sorted_top_similarity_df[\"Train_Patient_Name\"] = sorted_top_similarity_df[\"Train_Image\"].str.split('_').str[0]\n",
    "    sorted_top_similarity_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Drop duplicate patients and keep first entry only. \n",
    "    filtered_sorted_top_similarity_df = sorted_top_similarity_df.drop_duplicates(subset='Train_Patient_Name', keep='first').reset_index(drop=True)\n",
    "\n",
    "    \n",
    "    keep_only_filtered_sorted_top_similarity_df = filtered_sorted_top_similarity_df.head(n_imgs)\n",
    "    \n",
    "    #%% Plot the patient-level top similarities\n",
    "    # Plot the test image\n",
    "    ax = axes[row_pointer+1, 0]\n",
    "    ax.imshow(test_image, cmap='gray')\n",
    "    ax.set_title(f\"Test Image, GT: {test_label}, Pred: {test_pred}\")  \n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Plot patient-level training images\n",
    "    for column_pointer, row in enumerate(keep_only_filtered_sorted_top_similarity_df.itertuples()):\n",
    "        # train_image_path = f\"path_to_train_images/{row.Train_Image}_image.nii.gz\"  # Replace with actual path\n",
    "        train_image = read_image(train_im_dir, row.Train_Image + \"_image.nii.gz\")\n",
    "        if blend: \n",
    "                train_mask = read_image(train_im_dir, row.Train_Image + \"_mask.nii.gz\")\n",
    "                train_image = color_blend(train_image, train_mask, mask_color=mask_color, transparency_factor=transparency_factor)\n",
    "    \n",
    "        ax = axes[row_pointer+1, column_pointer + 1]  # First column is for the test image\n",
    "        ax.imshow(train_image, cmap='gray')\n",
    "        # ax.set_title(f\"Train {column_pointer + 1}, Label: {row.Train_Label}, \"\n",
    "        #                       f\"CV: {row.Model_Index+1}, \"\n",
    "        #                       f\"Cosine: {row.Cosine_Similarity:.4f}, MSE: {row.MSE:.4f}\")\n",
    "        ax.set_title(f\"{row.Train_Image}\\n Label: {row.Train_Label}, \"\n",
    "                          f\"CV: {row.Model_Index+1}, \"\n",
    "                          f\"Cosine: {row.Cosine_Similarity:.4f}, MSE: {row.MSE:.4f}\")\n",
    "        ax.axis('off')\n",
    "    \n",
    "    # Adjust layout and save the combined figure\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.9])\n",
    "    plt.savefig(os.path.join(save_dir, f\"{patient_name}.png\"))\n",
    "    if visualize: plt.show()\n",
    "    \n",
    "    \"Part IV: Count frequency of training patients appeared in image-level top similarities.\"\n",
    "    frequency_df = sorted_top_similarity_df['Train_Patient_Name'].value_counts()\n",
    "    frequency_df = frequency_df.reset_index()\n",
    "    frequency_df.columns = ['Train_Patient_Name', 'Frequency']\n",
    "\n",
    "    return top_similarity_df, filtered_sorted_top_similarity_df, frequency_df\n",
    "        # top_similarity_df: store top similarities for each model at the image-level\n",
    "        # filtered_sorted_top_similarity_df: top patient-level similarities from the image-level similarities. Training patient names are added\n",
    "        # frequency_df: how many times a training patient appears in the top image-level similarities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d632a208-7d50-4ec8-b25e-163fd370c071",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patient_info(patients_info, target_patient_names, keys, save_dir):\n",
    "    \"\"\"\n",
    "    This function extracts patients' clinical info. \n",
    "    \n",
    "    Args\n",
    "    ==============\n",
    "    patients_info: Patients' clinical info, csv file.\n",
    "    target_patient_names: List, the names of the target patients. \n",
    "    keys: Keys (features) that will be extracted.\n",
    "    save_dir: Directory to save the extracted clinical info.\n",
    "\n",
    "    Returns\n",
    "    ==============\n",
    "    target_patient_info: A dataframe containing clinical info of the target patients\n",
    "    \"\"\"\n",
    "    \n",
    "    # Keep keys only, remove other columns\n",
    "    filtered_patients_info = patients_info[keys]\n",
    "\n",
    "    # # Patient names\n",
    "    # target_patient_names = patient_level_similarity.iloc[0:3][\"Train_Image\"].tolist()\n",
    "    \n",
    "    target_patients_info = filtered_patients_info.loc[filtered_patients_info[\"Filename\"].isin(target_patient_names)]\n",
    "    \n",
    "    # # Save the result\n",
    "    # target_patient_info.to_excel(save_dir, index=False)\n",
    "\n",
    "    return target_patients_info\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dbcc2551-9976-4872-a300-557460a77d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_pca(patient_name:str, \n",
    "            train_df, \n",
    "            test_df,\n",
    "            top_similarity_df,\n",
    "            save_dir:str,\n",
    "            train_labelsize:list=[198, 159],\n",
    "            visualize:bool=False):\n",
    "\n",
    "    \"\"\"\n",
    "    This function calculates PCA. It collects feature embeddings from the training dataframe. It also collects feature\n",
    "    embeddings of the given patient from the test dataframe. Once all the feature embeddings are collected, it calculates\n",
    "    top 2 PCs. It plots training feature embeddings as benign and malignant with different colors. It also plots top training\n",
    "    feature embeddings with different colors to separate them from the remaining training feature embeddings. Finally, it plots\n",
    "    test feature embeddings. \n",
    "\n",
    "    Args:\n",
    "    ====================\n",
    "    patient_name: Name of the patient (e.g. \"PN0085_8960_20190103\")\n",
    "    train_df: It is the dataframe that contains training image names, labels, model indices, and features.\n",
    "    test_df: It is the dataframe that contains training image names, labels, predictions, model indices, and features.\n",
    "    top_similarity_df: It is the dataframe that contains patient-level similarity scores for all models.\n",
    "    save_dir: Directory to save the PCA plots.\n",
    "    train_labelsize: It is a list that contains no. of benign and malignant images in the training dataset.\n",
    "    visualize: Whether to visualize the plot.    \n",
    "    \"\"\"\n",
    "\n",
    "    # Group training data by model_idx\n",
    "    groupby_modelidx_train = train_df.groupby(\"Model_Index\")\n",
    "    n_groupby_modelidx = groupby_modelidx_train.ngroups  # no. of groups based on model_idx\n",
    "    # print(\"No. of groups based on model_idx:\", n_groupby_modelidx)\n",
    "    \n",
    "    # Create subplots arranged horizontally\n",
    "    fig, axs = plt.subplots(1, n_groupby_modelidx, figsize=(6 * n_groupby_modelidx, 6), constrained_layout=True)\n",
    "    fig.suptitle(f'PCA Visualization for Patient: {patient_name}', fontsize=16)\n",
    "    \n",
    "    # If there's only one subplot, wrap axs in a list for consistent indexing\n",
    "    if n_groupby_modelidx == 1: axs = [axs]\n",
    "\n",
    "    cnt_benign, cnt_malignant = [], []\n",
    "    \n",
    "    for model_idx in range(n_groupby_modelidx):\n",
    "        # Prepare test features\n",
    "        patient_data = test_df.loc[(test_df['Model_Index'] == model_idx) & (test_df['Name'] == patient_name)]\n",
    "        test_features = patient_data.iloc[:, 4:] # first four columns are not features\n",
    "    \n",
    "        # Prepare training features. \n",
    "        group_modelidx_train = groupby_modelidx_train.get_group(model_idx).reset_index(drop=True) # collect information for the current model index\n",
    "        train_features = group_modelidx_train.iloc[:, 3:]  # first three columns are not features\n",
    "    \n",
    "        # Combine train and test features\n",
    "        combined_features = np.vstack([train_features, test_features])\n",
    "        \n",
    "        # Standardize the combined features\n",
    "        scaler = StandardScaler()\n",
    "        combined_features = scaler.fit_transform(combined_features)\n",
    "    \n",
    "        # Extract top training image names in a list from the similarity dataframe for the current model index\n",
    "        top_trainnames = top_similarity_df[top_similarity_df[\"Model_Index\"] == model_idx][\"Train_Image\"].tolist()\n",
    "    \n",
    "        # Find indices of the top training images in group_modelidx_train dataframe\n",
    "        indices = group_modelidx_train.index[group_modelidx_train['Name'].isin(top_trainnames)].tolist()\n",
    "        \n",
    "        \"Apply PCA to reduce dimensions\"\n",
    "        pca = PCA(n_components=2)\n",
    "        pca_embeddings = pca.fit_transform(combined_features)\n",
    "        \n",
    "        # Separate transformed train and test embeddings\n",
    "        train_pca_embeddings_benign = pca_embeddings[:train_labelsize[0]] # train benign\n",
    "        train_pca_embeddings_malignant = pca_embeddings[train_labelsize[0]:len(train_features)] # train malignant\n",
    "        test_pca_embeddings = pca_embeddings[len(train_features):] # test image\n",
    "        \n",
    "        # Extract PCA-transformed embeddings for the highlighted indices (top similarities)\n",
    "        top_benign = train_pca_embeddings_benign[np.array(indices)[np.array(indices) < train_labelsize[0]]]\n",
    "        top_malignant = train_pca_embeddings_malignant[np.array(indices)[np.array(indices) >= train_labelsize[0]] - train_labelsize[0]]\n",
    "\n",
    "        cnt_benign.append(len(top_benign))\n",
    "        cnt_malignant.append(len(top_malignant))\n",
    "        \n",
    "        print(f\"Variance ratio for model {model_idx}:\", pca.explained_variance_ratio_)\n",
    "        \n",
    "        \"Scatter plot for PCA-transformed embeddings\"\n",
    "        # Plot training images as benign or malignant\n",
    "        axs[model_idx].scatter(train_pca_embeddings_benign[:, 0], train_pca_embeddings_benign[:, 1], alpha=0.5, label=\"Train_benign\", color='blue')\n",
    "        axs[model_idx].scatter(train_pca_embeddings_malignant[:, 0], train_pca_embeddings_malignant[:, 1], alpha=0.5, label=\"Train_malignant\", color='orange')\n",
    "        \n",
    "        # Highlight the specified training images\n",
    "        axs[model_idx].scatter(top_benign[:, 0], top_benign[:, 1], label=\"Top_benign\", color='cyan', edgecolors='black', linewidths=2, s=50)\n",
    "        axs[model_idx].scatter(top_malignant[:, 0], top_malignant[:, 1], label=\"Top_malignant\", color='gold', edgecolors='black', linewidths=2, s=50)\n",
    "    \n",
    "        # Plot the test image\n",
    "        axs[model_idx].scatter(test_pca_embeddings[:, 0], test_pca_embeddings[:, 1], alpha=0.5, label=\"Test\", marker='o', color='red', edgecolors='black', linewidths=2, s=100)\n",
    "        \n",
    "        axs[model_idx].legend()    \n",
    "        axs[model_idx].set_title(f'PCA Visualization for Model Index {model_idx}')\n",
    "        axs[model_idx].set_xlabel('Principal Component 1')\n",
    "        axs[model_idx].set_ylabel('Principal Component 2')\n",
    "    \n",
    "    # Show the combined plot\n",
    "    plt.savefig(os.path.join(save_dir, f\"{patient_name}_pca.png\")) \n",
    "    if visualize: plt.show()\n",
    "\n",
    "    return cnt_benign, cnt_malignant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2de98930-10ad-421a-ace7-3b90015cdf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_tsne(patient_name:str, \n",
    "            train_df, \n",
    "            test_df,\n",
    "            top_similarity_df,\n",
    "            save_dir:str,\n",
    "            train_labelsize:list=[198, 159],\n",
    "            perplexity:int=50, \n",
    "            n_iter:int=1000,\n",
    "            visualize:bool=False):\n",
    "\n",
    "    \"\"\"\n",
    "    This function calculates t-SNE. It collects feature embeddings from the training dataframe. It also collects feature\n",
    "    embeddings of the given patient from the test dataframe. Once all the feature embeddings are collected, it calculates\n",
    "    top 2 t-SNE components. It plots training feature embeddings as benign and malignant with different colors. It also plots top training\n",
    "    feature embeddings with different colors to separate them from the remaining training feature embeddings. Finally, it plots\n",
    "    test feature embeddings. \n",
    "\n",
    "    Args:\n",
    "    ====================\n",
    "    patient_name: Name of the patient (e.g. \"PN0085_8960_20190103\")\n",
    "    train_df: It is the dataframe that contains training image names, labels, model indices, and features.\n",
    "    test_df: It is the dataframe that contains training image names, labels, predictions, model indices, and features.\n",
    "    top_similarity_df: It is the dataframe that contains patient-level similarity scores for all models.\n",
    "    save_dir: Directory to save the PCA plots.\n",
    "    train_labelsize: It is a list that contains no. of benign and malignant images in the training dataset.\n",
    "    perplexity: It influences how many neighbors are considered when estimating the local data distribution.\n",
    "                It typically considers about 3×perplexity nearest neighbors during the computation of conditional probabilities. \n",
    "                Small datasets (<1000 points): Lower perplexity (5–30). Large datasets: Higher perplexity (30–50).\n",
    "    n_iter: No. of iterations to perform t-SNE.\n",
    "    visualize: Whether to visualize the plot.    \n",
    "    \"\"\"    \n",
    "\n",
    "    # Group training data by model_idx\n",
    "    groupby_modelidx_train = train_df.groupby(\"Model_Index\")\n",
    "    n_groupby_modelidx = groupby_modelidx_train.ngroups  # no. of groups based on model_idx\n",
    "    \n",
    "    # Create subplots arranged horizontally\n",
    "    fig, axs = plt.subplots(1, n_groupby_modelidx, figsize=(6 * n_groupby_modelidx, 6), constrained_layout=True)\n",
    "    fig.suptitle(f't-SNE Visualization for Patient: {patient_name}', fontsize=16)\n",
    "    \n",
    "    # If there's only one subplot, wrap axs in a list for consistent indexing\n",
    "    if n_groupby_modelidx == 1: axs = [axs]\n",
    "\n",
    "    cnt_benign, cnt_malignant = [], [] # count #benign and #malignant\n",
    "    \n",
    "    for model_idx in range(n_groupby_modelidx):\n",
    "        # Prepare test features\n",
    "        patient_data = test_df.loc[(test_df['Model_Index'] == model_idx) & (test_df['Name'] == patient_name)]\n",
    "        test_features = patient_data.iloc[:, 4:]  # first four columns are not features\n",
    "    \n",
    "        # Prepare training features\n",
    "        group_modelidx_train = groupby_modelidx_train.get_group(model_idx).reset_index(drop=True)\n",
    "        train_features = group_modelidx_train.iloc[:, 3:]  # first three columns are not features\n",
    "    \n",
    "        # Combine train and test features\n",
    "        combined_features = np.vstack([train_features, test_features])\n",
    "        \n",
    "        # Standardize the combined features\n",
    "        scaler = StandardScaler()\n",
    "        combined_features = scaler.fit_transform(combined_features)\n",
    "    \n",
    "        # Extract top training image names in a list from the similarity dataframe for the current model index\n",
    "        top_trainnames = top_similarity_df[top_similarity_df[\"Model_Index\"] == model_idx][\"Train_Image\"].tolist()\n",
    "    \n",
    "        # Find indices of the top training images in group_modelidx_train dataframe\n",
    "        indices = group_modelidx_train.index[group_modelidx_train['Name'].isin(top_trainnames)].tolist()\n",
    "        \n",
    "        \"Apply t-SNE to reduce dimensions\"\n",
    "        tsne = TSNE(n_components=2, perplexity=perplexity, n_iter=n_iter, random_state=42)\n",
    "        tsne_embeddings = tsne.fit_transform(combined_features)\n",
    "        \n",
    "        # Separate transformed train and test embeddings\n",
    "        train_tsne_embeddings_benign = tsne_embeddings[:train_labelsize[0]]  # train benign\n",
    "        train_tsne_embeddings_malignant = tsne_embeddings[train_labelsize[0]:len(train_features)]  # train malignant\n",
    "        test_tsne_embeddings = tsne_embeddings[len(train_features):]  # test image\n",
    "        \n",
    "        # Extract t-SNE-transformed embeddings for the highlighted indices (top similarities)\n",
    "        top_benign = train_tsne_embeddings_benign[np.array(indices)[np.array(indices) < train_labelsize[0]]]\n",
    "        top_malignant = train_tsne_embeddings_malignant[np.array(indices)[np.array(indices) >= train_labelsize[0]] - train_labelsize[0]]\n",
    "\n",
    "        cnt_benign.append(len(top_benign))\n",
    "        cnt_malignant.append(len(top_malignant))\n",
    "        \n",
    "        \"Scatter plot for t-SNE-transformed embeddings\"\n",
    "        # Plot training images as benign or malignant\n",
    "        axs[model_idx].scatter(train_tsne_embeddings_benign[:, 0], train_tsne_embeddings_benign[:, 1], alpha=0.5, label=\"Train_benign\", color='blue')\n",
    "        axs[model_idx].scatter(train_tsne_embeddings_malignant[:, 0], train_tsne_embeddings_malignant[:, 1], alpha=0.5, label=\"Train_malignant\", color='orange')\n",
    "        \n",
    "        # Highlight the specified training images\n",
    "        axs[model_idx].scatter(top_benign[:, 0], top_benign[:, 1], label=\"Top_benign\", color='cyan', edgecolors='black', linewidths=2, s=50)\n",
    "        axs[model_idx].scatter(top_malignant[:, 0], top_malignant[:, 1], label=\"Top_malignant\", color='gold', edgecolors='black', linewidths=2, s=50)\n",
    "    \n",
    "        # Plot the test image\n",
    "        axs[model_idx].scatter(test_tsne_embeddings[:, 0], test_tsne_embeddings[:, 1], alpha=0.5, label=\"Test\", marker='o', color='red', edgecolors='black', linewidths=2, s=100)\n",
    "        \n",
    "        axs[model_idx].legend()\n",
    "        axs[model_idx].set_title(f't-SNE Visualization for Model Index {model_idx}')\n",
    "        axs[model_idx].set_xlabel('t-SNE Dimension 1')\n",
    "        axs[model_idx].set_ylabel('t-SNE Dimension 2')\n",
    "    \n",
    "    # Show the combined plot\n",
    "    plt.savefig(os.path.join(save_dir, f\"{patient_name}_tsne.png\")) \n",
    "    if visualize: plt.show()\n",
    "\n",
    "    return cnt_benign, cnt_malignant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ef084f-a8dd-4e01-a80f-1e864c8dd211",
   "metadata": {},
   "source": [
    "### Create dataframe for training features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc9f72aa-4b1c-4519-8667-1ddddef054bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_data = []  # Use a list to collect all rows before creating the DataFrame\n",
    "for data_per_model in store_train_features:\n",
    "    for data in data_per_model: \n",
    "        # fromat of data: name, label, features, model_idx\n",
    "        # Create a dictionary for the current row\n",
    "        row_dict = {\n",
    "            \"Name\": data[0],\n",
    "            \"Label\": data[1],\n",
    "            \"Model_Index\": data[3], \n",
    "        }\n",
    "        \n",
    "        # Add embeddings as key-value pairs to the dictionary\n",
    "        row_dict.update({f\"Feature_{j}\": value for j, value in enumerate(data[2])})\n",
    "\n",
    "        # Append the row dictionary to the list\n",
    "        collect_data.append(row_dict)\n",
    "\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "train_df = pd.DataFrame(collect_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef60011-8ed4-491c-b9a9-7ece77e7669e",
   "metadata": {},
   "source": [
    "### Create dataframe for test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a210ea4-cd90-4474-b8c4-f2275d4c29b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_data = []  # Use a list to collect all rows before creating the DataFrame\n",
    "for data_per_model in store_test_features:\n",
    "    for data in data_per_model: \n",
    "        # fromat of data: name, label, features, model_idx\n",
    "        # Create a dictionary for the current row\n",
    "        row_dict = {\n",
    "            \"Name\": data[0],\n",
    "            \"Label\": data[1],\n",
    "            \"Prediction\": data[3],\n",
    "            \"Model_Index\": data[4], \n",
    "        }\n",
    "        \n",
    "        # Add embeddings as key-value pairs to the dictionary\n",
    "        row_dict.update({f\"Feature_{j}\": value for j, value in enumerate(data[2])})\n",
    "\n",
    "        # Append the row dictionary to the list\n",
    "        collect_data.append(row_dict)\n",
    "\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "test_df = pd.DataFrame(collect_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70430b68-dac3-4a86-a953-dd8966f1a5eb",
   "metadata": {},
   "source": [
    "#### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a408dd5-8a8d-4bf3-a6f5-05faca479e9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "keep_range = (0,4) # (354,356)\n",
    "\n",
    "test_names = [\"XYZ_1\", \"XYZ_2\", \"XYZ_3\"] # Replace with actual test names\n",
    "\n",
    "# Create dataframes to store confidence scores\n",
    "df_pca, df_tsne, df_models = [], [], [] # the list will be converted to dataframe after all iterations\n",
    "\n",
    "for i, patient_name in enumerate(test_names):\n",
    "    print(f\"{i}. Processing {patient_name}\")\n",
    "\n",
    "    # Patient label and prediction\n",
    "    test_pred = int(test_results.loc[test_results[\"Names\"]==patient_name][\"Prediction\"].values)\n",
    "    test_label = int(test_results.loc[test_results[\"Names\"]==patient_name][\"Label\"].values)\n",
    "\n",
    "    # Not saving the dataframes. \n",
    "    top_similarity_df, filtered_sorted_top_similarity_df, frequency_df = post_similarity(detailed_results_df, patient_name, N_FOLDS,\n",
    "                train_im_dir, test_im_dir, test_save_dir, \n",
    "                sort_by='Cosine_Similarity', keep_range=keep_range, \n",
    "                blend=False, visualize=False)\n",
    "\n",
    "    \"Uncomment to collect patient-label info\"\n",
    "    # # Read patients_info csv file\n",
    "    # patients_info_file = \"/research/m324371/Project/adnexal/radiomic_and_clinical_files/LabelStudio_DICOM_redCap_results.csv\" \n",
    "    # patients_info = pd.read_csv(patients_info_file)\n",
    "\n",
    "    # # Extract target patient names (test + top patient-level training images)\n",
    "    # target_patient_names = [patient_name] +  filtered_sorted_top_similarity_df.iloc[0:3][\"Train_Image\"].tolist()\n",
    "\n",
    "    # # Keys (features) to extract\n",
    "    # keys = [\"Filename\", \"dimension 2\", \"dimension 3\", \"Other solid component?\", \"Largest solid component max diameter\", \"lesion category\", \"internal wall\",\n",
    "    #     \"Simple cyst? (unilocular, smooth internal wall, anechoic)\", \"acoustic shadows\", \"Color score\", \"Maximum dimension\"]\n",
    "\n",
    "    # # Save directory\n",
    "    # save_dir = os.path.join(test_save_dir, patient_name + \"_\" + str(keep_range) + \".xlsx\")\n",
    "\n",
    "    # # Run the function\n",
    "    # target_patients_info = get_patient_info(patients_info, target_patient_names, keys, save_dir)\n",
    "\n",
    "    # # Save the result\n",
    "    # target_patients_info.to_excel(save_dir, index=False)\n",
    "\n",
    "    \"Uncomment to calculate PCA\"\n",
    "    cnt_benign, cnt_malignant = cal_pca(patient_name=patient_name, \n",
    "                                        train_df=train_df, \n",
    "                                        test_df=test_df,\n",
    "                                        top_similarity_df=top_similarity_df,\n",
    "                                        save_dir=test_save_dir,\n",
    "                                        train_labelsize=[198, 159],\n",
    "                                        visualize=False)\n",
    "    \n",
    "    # PCA confidence score\n",
    "    pca_confidence = sum(cnt_benign)/(sum(cnt_benign)+sum(cnt_malignant)) if test_label==0 else sum(cnt_malignant)/(sum(cnt_benign)+sum(cnt_malignant))\n",
    "    pca_row = {\"Name\":patient_name, \"Label\":test_label, \"Prediction\":test_pred, \"Cnt_benign\":cnt_benign, \"Cnt_malignant\":cnt_malignant, \"Confidence\":pca_confidence}    \n",
    "    df_pca.append(pca_row)\n",
    "\n",
    "    \"Uncomment to calculate t-SNE\"\n",
    "    cnt_benign, cnt_malignant = cal_tsne(patient_name=patient_name, \n",
    "                                        train_df=train_df, \n",
    "                                        test_df=test_df,\n",
    "                                        top_similarity_df=top_similarity_df,\n",
    "                                        save_dir=test_save_dir,\n",
    "                                        train_labelsize=[198, 159],\n",
    "                                        perplexity=50,\n",
    "                                        n_iter=1000,\n",
    "                                        visualize=False)\n",
    "\n",
    "    # t-SNE confidence score\n",
    "    tsne_confidence = sum(cnt_benign)/(sum(cnt_benign)+sum(cnt_malignant)) if test_label==0 else sum(cnt_malignant)/(sum(cnt_benign)+sum(cnt_malignant))\n",
    "    tsne_row = {\"Name\":patient_name, \"Label\":test_label, \"Prediction\":test_pred, \"Cnt_benign\":cnt_benign, \"Cnt_malignant\":cnt_malignant, \"Confidence\":tsne_confidence}    \n",
    "    df_tsne.append(tsne_row)\n",
    "\n",
    "    \"Uncomment to calculated confidence score w.r.t. models\"\n",
    "    model_outputs = test_df[test_df[\"Name\"]==patient_name][\"Prediction\"].tolist() # output is like [0,0,1,0,1]\n",
    "    n_benign, n_malignant = model_outputs.count(0), model_outputs.count(1)\n",
    "    model_confidence = n_benign/(n_benign+n_malignant) if test_label==0 else n_malignant/(n_benign+n_malignant)\n",
    "    model_row = {\"Name\":patient_name, \"Label\":test_label, \"Prediction\":test_pred, \"Outputs\":model_outputs, \"Confidence\":model_confidence}    \n",
    "    df_models.append(model_row)\n",
    "    \n",
    "# Convert list to dataframe\n",
    "df_pca = pd.DataFrame(df_pca)\n",
    "df_tsne = pd.DataFrame(df_tsne)\n",
    "df_models = pd.DataFrame(df_models)\n",
    "\n",
    "# Save the dataframes\n",
    "df_pca.to_excel(os.path.join(test_save_dir, \"pca_score.xlsx\"), index=False)\n",
    "df_tsne.to_excel(os.path.join(test_save_dir, \"tsne_score.xlsx\"), index=False)\n",
    "df_models.to_excel(os.path.join(test_save_dir, \"models_score.xlsx\"), index=False)\n",
    "\n",
    "print(\"Processing done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fa2711-6c38-4dff-9beb-3b613dbcebb3",
   "metadata": {},
   "source": [
    "### MAP@K for image-to-image retrieval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1d487a-7091-4bc8-b027-d91940ad6c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(relevant_labels, k):\n",
    "    \"\"\"Compute precision at K\"\"\"\n",
    "    relevant_k = relevant_labels[:k]  # Top K retrieved results\n",
    "    return np.sum(relevant_k) / k  # Fraction of relevant instances\n",
    "\n",
    "def average_precision_at_k(relevant_labels, k):\n",
    "    \"\"\"Compute AP@K for a single test image\"\"\"\n",
    "    num_relevant = np.sum(relevant_labels[:k])  # Count relevant results in top K\n",
    "    if num_relevant == 0:\n",
    "        return 0\n",
    "    ap_k = sum(precision_at_k(relevant_labels, i+1) for i in range(k) if relevant_labels[i]) / num_relevant\n",
    "    return ap_k\n",
    "\n",
    "def mean_average_precision_at_k(df, k):\n",
    "    \"\"\"Compute MAP@K for each Model_Index\"\"\"\n",
    "    map_scores = {}\n",
    "\n",
    "    for model_idx, model_df in df.groupby(\"Model_Index\"):\n",
    "        ap_scores = []\n",
    "        \n",
    "        for test_image, group in model_df.groupby(\"Test_Image\"):\n",
    "            sorted_group = group.sort_values(by=\"Cosine_Similarity\", ascending=False)  # Sort by similarity\n",
    "            relevant_labels = (sorted_group[\"Test_Label\"] == sorted_group[\"Train_Label\"]).astype(int).values  # Binary relevance\n",
    "            ap_k = average_precision_at_k(relevant_labels, k)\n",
    "            ap_scores.append(ap_k)\n",
    "        \n",
    "        map_scores[model_idx] = np.mean(ap_scores)  # Compute MAP@K for the model\n",
    "    \n",
    "    return map_scores\n",
    "\n",
    "# Uncomment to load detailed_results_df from excel file\n",
    "# file_path = \"similarity_test_v7-3_top5/train_test_similarity_2025-01-28_20-45-36.xlsx\"\n",
    "# detailed_results_df = pd.read_excel(file_path)\n",
    "\n",
    "K = 50  # Define the value of K\n",
    "\n",
    "# Compute MAP@K for each model\n",
    "map_at_k_results = mean_average_precision_at_k(detailed_results_df, K)\n",
    "\n",
    "# Print results\n",
    "for model_idx, map_k in map_at_k_results.items():\n",
    "    print(f\"Model {model_idx} - MAP@{K}: {map_k:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
