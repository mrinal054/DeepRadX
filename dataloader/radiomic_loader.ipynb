{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95f8c7a4-9c8b-4b2a-adb5-81146ea82a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAuthor @ Mrinal Kanti Dhar\\nOctober 6, 2024\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Author @ Mrinal Kanti Dhar\n",
    "October 6, 2024\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc9041f2-5015-43ce-b70a-7703edab883a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import albumentations as A\n",
    "from preprocessing_v2 import preprocess\n",
    "import nibabel as nib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e7b1038-81e8-4d87-8394-364b7479a912",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 dataframe, \n",
    "                 n_classes:int=None, \n",
    "                 transform=None, \n",
    "                 normalize=None,\n",
    "                 one_hot:bool=None,\n",
    "                 preprocess_dict:dict=None,\n",
    "                 concat:list=None,\n",
    "                 radiomic_feature_names:list=None,\n",
    "                 radiomic_dataframe=None,\n",
    "                ):\n",
    "        \n",
    "        self.dataframe = dataframe\n",
    "        self.n_classes = n_classes\n",
    "        self.transform = transform\n",
    "        self.normalize = normalize\n",
    "        self.one_hot = one_hot \n",
    "        self.preprocess_dict = preprocess_dict\n",
    "        self.concat = concat\n",
    "        self.radiomic_feature_names = radiomic_feature_names\n",
    "        self.radiomic_dataframe = radiomic_dataframe\n",
    "           \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\" Load images, labels, and image name \"\"\"\n",
    "        name = self.dataframe[\"Base names\"][index] # image location\n",
    "        \n",
    "        # Do preprocessing\n",
    "        pp_out_dict = preprocess(name=name, **self.preprocess_dict)\n",
    "\n",
    "        image = pp_out_dict[\"image\"]\n",
    "        mask = pp_out_dict[\"mask\"]\n",
    "        adnexal = pp_out_dict[\"adnexal\"]\n",
    "        fluid = pp_out_dict[\"fluid\"]\n",
    "        solid = pp_out_dict[\"solid\"]\n",
    "\n",
    "        # Create multi-channel image if self.concat, otherwise make a copy of 'image'\n",
    "        if self.concat is not None:\n",
    "            list_imgs = []\n",
    "            for key in self.concat: # list images defined by self.concat\n",
    "                if key in pp_out_dict: list_imgs.append(pp_out_dict[key])\n",
    "                else: raise ValueError(f\"Key '{key}' not found in the dictionary. Possible keys are: image, adnexal, fluid, solid, and mask.\")\n",
    "            \n",
    "            im = np.stack(list_imgs, axis=-1) \n",
    "        else: im = image.copy()\n",
    "\n",
    "        # Augmentation\n",
    "        if self.transform: im = self.transform(image=im)['image']\n",
    "\n",
    "        # Normalize\n",
    "        if self.normalize: im = self.normalize(image=im)['image']\n",
    "\n",
    "        # Convert to tensor (always) \n",
    "        im = torch.from_numpy(im).permute(2,0,1).float() # change HWC to CHW\n",
    "\n",
    "        # Get the class value\n",
    "        y = self.dataframe[\"Class\"][index] # classes\n",
    "        \n",
    "        # One-hot\n",
    "        if self.one_hot: y = torch.tensor(np.eye(self.n_classes)[y], dtype=torch.float32)  # One-hot encoded tensor\n",
    "        else: y = torch.tensor(y, dtype=torch.float).unsqueeze(0)   # Scalar label as a tensor\n",
    "\n",
    "        \"\"\" Load radiomic features \"\"\"\n",
    "        if self.radiomic_feature_names is not None:\n",
    "            # Ensure proper data is being loaded. Check the names in image dataframe and radiomic dataframe. \n",
    "            # If both names are same, then it is loading properly.\n",
    "            radiomic_name = self.radiomic_dataframe[\"Base names\"][index] \n",
    "            if radiomic_name != name:\n",
    "                raise ValueError(f\"Attempting incorrect loading. The image name is {name}, but the radiomic name is {radiomic_name}\")\n",
    "\n",
    "            # Collect radiomic features\n",
    "            radiomic_features = [self.radiomic_dataframe.iloc[index][name] for name in self.radiomic_feature_names]\n",
    "\n",
    "            # radiomic_features is a vector. Convert it to a tensor of shape 1 x num_features.\n",
    "            radiomic_features = torch.tensor(radiomic_features, dtype=torch.float) # torch.Size([num_features])\n",
    "            radiomic_features = radiomic_features.unsqueeze(dim=0) # torch.Size([1, num_features])\n",
    "\n",
    "            return im, radiomic_features, y, name # tensors\n",
    "            \n",
    "        else:           \n",
    "            return im, y, name # tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c440706-13a5-4421-a66b-0301c46e97b1",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3007000f-5cf8-4a47-9d86-6aaa3a374c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 256, 256]) torch.Size([1, 3]) torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "#Test Run\n",
    "#%% Parameters\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 32\n",
    "ONE_HOT = True\n",
    "N_CLASSES = 2\n",
    "ONLY_ADNEXAL = False\n",
    "ONLY_FLUID = True\n",
    "ONLY_SOLID = True\n",
    "DRAW_BBOX = False\n",
    "CROP_ROI = True\n",
    "MARGIN = 200\n",
    "RESIZE = True\n",
    "KEEP_ASPECT_RATIO = True\n",
    "TARGET_SIZE = (256,256)\n",
    "CONCAT = [\"image\", \"solid\", \"fluid\"] # Possible keywords are \"image\", \"adnexal\", \"fluid\", \"solid\", \"mask\"\n",
    "\n",
    "# Read dataframe\n",
    "df_file = '/research/m324371/Project/adnexal/adnexal_dataset_all.xlsx'\n",
    "\n",
    "df = pd.read_excel(df_file, sheet_name=None) \n",
    "\n",
    "# Read train and test sheets\n",
    "train_df = df['train']  # dataframe has a column for image names and another \n",
    "                        # column for class values\n",
    "\n",
    "train_df = train_df.sort_values(by='Base names').reset_index(drop=True)\n",
    "\n",
    "radiomic_train_dir = '/research/m324371/Project/adnexal/radiomic_files/Adnex_v2_radiomic_features_Params_filters_32_demo-train_val.csv' \n",
    "radiomic_train_df = pd.read_csv(radiomic_train_dir)\n",
    "radiomic_train_df = radiomic_train_df.sort_values(by='Base names').reset_index(drop=True)\n",
    "\n",
    "train_im_dir = '/research/m324371/Project/adnexal/dataset/train'\n",
    "\n",
    "# Example normalization for grayscale images\n",
    "normalize_transform = A.Compose([A.Normalize(mean=(0,), std=(1,))]) # Example normalization for grayscale images\n",
    "# normalize_transform = A.Compose([A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))], p=1) # always normalize\n",
    "\n",
    "# Define the transformation pipeline\n",
    "transform_list = [\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    \n",
    "    A.OneOf(\n",
    "        [\n",
    "            A.ShiftScaleRotate(scale_limit=0.15, rotate_limit=0, shift_limit=0, p=0.5, border_mode=0), # scale only\n",
    "            A.ShiftScaleRotate(scale_limit=0, rotate_limit=10, shift_limit=0, p=0.5, border_mode=0), # rotate only\n",
    "            A.ShiftScaleRotate(scale_limit=0, rotate_limit=0, shift_limit=0.1, p=0.5, border_mode=0), # shift only\n",
    "            A.ShiftScaleRotate(scale_limit=0.15, rotate_limit=10, shift_limit=0.1, p=0.5, border_mode=0), # affine transform\n",
    "        ], p=0.7\n",
    "    ),\n",
    "       \n",
    "    A.ElasticTransform(alpha=3.0, sigma=50.0, alpha_affine=None, p=0.5),\n",
    "]\n",
    "\n",
    "train_transform = A.Compose(transform_list, p=0.0) # do augmentation 90% time\n",
    "\n",
    "train_pp_dict = {}\n",
    "train_pp_dict[\"file_dir\"] = train_im_dir\n",
    "train_pp_dict[\"only_adnexal\"] = ONLY_ADNEXAL\n",
    "train_pp_dict[\"only_fluid\"] = ONLY_FLUID\n",
    "train_pp_dict[\"only_solid\"] = ONLY_SOLID\n",
    "train_pp_dict[\"draw_bbox\"] = DRAW_BBOX\n",
    "train_pp_dict[\"crop_roi\"] = CROP_ROI\n",
    "train_pp_dict[\"margin\"] = MARGIN\n",
    "train_pp_dict[\"resize\"] = RESIZE\n",
    "train_pp_dict[\"keep_aspect_ratio\"] = KEEP_ASPECT_RATIO\n",
    "train_pp_dict[\"target_size\"] = TARGET_SIZE\n",
    "\n",
    "# Radiomic features\n",
    "radiomic_feature_names = [\"original_glrlm_GrayLevelNonUniformityNormalized\",\n",
    "                          \"original_glszm_GrayLevelVariance\", \n",
    "                          \"original_glszm_SmallAreaHighGrayLevelEmphasis\",]\n",
    "\n",
    "\n",
    "train_dataset = MyDataset(\n",
    "    train_df, \n",
    "    n_classes=N_CLASSES, \n",
    "    transform=train_transform, \n",
    "    normalize=normalize_transform,\n",
    "    one_hot=ONE_HOT,\n",
    "    preprocess_dict=train_pp_dict,\n",
    "    concat=CONCAT,\n",
    "    radiomic_feature_names=radiomic_feature_names,\n",
    "    radiomic_dataframe=radiomic_train_df,\n",
    "    )\n",
    "\n",
    "itr = iter(train_dataset)\n",
    "x,rm,y,name = next(itr)\n",
    "print(x.shape, rm.shape, y.shape)\n",
    "x = x.numpy()\n",
    "x = np.transpose(x, [1,2,0])\n",
    "x0, x1, x2 = x[:,:,0], x[:,:,1], x[:,:,2]\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.figure(), plt.imshow(x)\n",
    "# plt.figure(), plt.imshow(x0, cmap='gray')\n",
    "# plt.figure(), plt.imshow(x1, cmap='gray')\n",
    "# plt.figure(), plt.imshow(x2, cmap='gray')\n",
    "\n",
    "# print(x.min(), x.max())\n",
    "# print(x0.min(), x0.max())\n",
    "# print(x1.min(), x1.max())\n",
    "# print(x2.min(), x2.max())\n",
    "\n",
    "# # Check dataloader\n",
    "# train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=1) \n",
    "# itr2 = iter(train_loader)\n",
    "# x, rm, y, name = next(itr2)\n",
    "\n",
    "# print(x.shape)\n",
    "# print(y.shape)\n",
    "\n",
    "\n",
    "# # In[ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "696378f4-11f6-41ae-97b3-cb094c32e941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1431,  1.0574,  1.2521]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9430b75-9c03-4c10-aabd-5e0e16e2fed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 256, 256]) torch.Size([1, 3]) torch.Size([2]) BPN0151_18_20190926\n"
     ]
    }
   ],
   "source": [
    "x,rm,y,name = next(itr)\n",
    "print(x.shape, rm.shape, y.shape, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2d8d94-6c96-420f-8648-f6b9bd936de6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
